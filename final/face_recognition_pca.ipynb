{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import linalg as la\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img, title = '', figsize=(20,10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.set_style(\"white\")\n",
    "    plt.imshow(img)\n",
    "    plt.gray()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def imgs_show(imgs, rows, fontsize=36):\n",
    "    fig = plt.figure()\n",
    "    sns.set_style(\"white\")\n",
    "    for n, (img, title) in enumerate(imgs):\n",
    "        a = fig.add_subplot(rows, np.ceil(len(imgs)/float(rows)), n + 1)\n",
    "        a.set_title(title, fontdict={\"fontsize\": fontsize})\n",
    "        plt.gray()\n",
    "        plt.imshow(img)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * len(imgs))\n",
    "    plt.show()\n",
    "    \n",
    "def read_folder(folder, ext):\n",
    "    images = []\n",
    "\n",
    "    for r, d, f in os.walk(folder):\n",
    "        for file in f:\n",
    "            if file.endswith(ext):\n",
    "                path = os.path.join(r, file)\n",
    "                images.append(cv2.imread(path, cv2.IMREAD_GRAYSCALE), info=path)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# FACES_LINK=\"http://mlsp.cs.cmu.edu/courses/fall2013/assignments/assignment2/lfw1000.zip\"\n",
    "# FACES_FILE_NAME=\"lfw1000.zip\"\n",
    "\n",
    "# NON_FACES_FILE_NAME=\"non_face.zip\"\n",
    "\n",
    "# download() {\n",
    "#     if [ -f \"$2\" ]; then\n",
    "#         echo \"$2 exist\"\n",
    "#     else \n",
    "#         curl \"$1\" --output \"$2\"\n",
    "#     fi\n",
    "# }\n",
    "\n",
    "# download $FACES_LINK $FACES_FILE_NAME\n",
    "\n",
    "# unzip $FACES_FILE_NAME\n",
    "# unzip att_faces.zip -d att_faces\n",
    "# unzip $NON_FACES_FILE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets LFW1000 and Linnaeus 5 64X64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ca0ca9a48bcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./lfw1000/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.pgm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnon_face_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./non_face/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Faces dataset: {}. Non-faces dataset: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_face_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c1a23c37d592>\u001b[0m in \u001b[0;36mread_folder\u001b[0;34m(folder, ext)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: append() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "images = np.array(read_folder('./lfw1000/', '.pgm'))\n",
    "non_face_images = np.array(read_folder('./non_face/', '.jpg'))\n",
    "\n",
    "print(\"Faces dataset: {}. Non-faces dataset: {}\".format(images.shape, non_face_images.shape))\n",
    "\n",
    "train, test = train_test_split(images, test_size=.2, random_state=512, shuffle=True)\n",
    "print(\"Train set shape: {}. Test set shape: {}\".format(train.shape, test.shape))\n",
    "\n",
    "_, non_face_test = train_test_split(non_face_images, test_size=.1, random_state=512)\n",
    "print(\"Non face test set shape: {}\".format(non_face_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration of FW1000 and Linnaeus 5 64X64 datasets\n",
    "\n",
    "Lets check sample from the dataset with faces and see the mean face. And also check non faces data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.seed(512)\n",
    "\n",
    "sample = [(images[i], \"\") for i in random.sample(range(0, len(images)), 10)]\n",
    "imgs_show(sample, 1)\n",
    "img_show(np.mean(images, axis=(0)), title=\"Mean face of dataset\", figsize=(4,3))\n",
    "\n",
    "imgs_show([(non_face_images[i], \"\") for i in random.sample(range(0, len(non_face_images)), 10)], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.mean = 0\n",
    "        self.normalized = None\n",
    "        self.cov = None\n",
    "        \n",
    "        self.desc_ordered_vals_indexes = None\n",
    "        self.eigenvals = None\n",
    "        self.eigenvecs = None\n",
    "        self.eigenfaces = None\n",
    "        \n",
    "        self.number_of_components = 0\n",
    "        self.weights = None\n",
    "        \n",
    "        self.threshold = 0\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.data = X\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.normalized = np.array([(x - self.mean).flatten() for x in self.data])\n",
    "        self.cov = self.normalized.dot(self.normalized.T)/self.normalized.shape[0]\n",
    "        \n",
    "        vals, vecs = la.eig(self.cov)\n",
    "        self.desc_ordered_vals_indexes = np.flip(np.argsort(vals))\n",
    "        \n",
    "        self.eigenvals = np.array([vals[i] for i in self.desc_ordered_vals_indexes])\n",
    "        self.eigenvecs = np.array([vecs[i] for i in self.desc_ordered_vals_indexes])\n",
    "        \n",
    "        eigenfaces = self.normalized[self.desc_ordered_vals_indexes].T.dot(self.eigenvecs)\n",
    "        self.eigenfaces = eigenfaces/la.norm(eigenfaces, axis=0)\n",
    "    \n",
    "    def calculate_weights(self, number_of_components):\n",
    "        eigenfaces_to_use = self.eigenfaces[:,:number_of_components]\n",
    "        training_data = np.array([(x - self.mean).flatten() for x in self.data])\n",
    "        \n",
    "        self.weights = np.dot(training_data, eigenfaces_to_use)\n",
    "        self.number_of_components = number_of_components\n",
    "        \n",
    "    def calculate_threshold(self):\n",
    "        distances = np.array([])\n",
    "        for i in range(self.number_of_components):\n",
    "            for j in range(i, self.number_of_components):\n",
    "                distances = np.append(distances, np.sqrt(la.norm(self.weights[i] - self.weights[j])))\n",
    "                \n",
    "        self.threshold = np.max(distances) / 2\n",
    "        return self.threshold\n",
    "    \n",
    "    def reduce_dimention(self, Y, number_of_components):\n",
    "        y_normalized = (Y - self.mean).flatten()[..., np.newaxis]\n",
    "        eigenfaces_to_use = self.eigenfaces[:, :number_of_components]\n",
    "        return eigenfaces_to_use.dot(eigenfaces_to_use.T).dot(y_normalized) + self.mean.flatten()[..., np.newaxis]\n",
    "    \n",
    "    def __find_weights(self, Y):\n",
    "        y_normalized = (Y - self.mean).flatten()[..., np.newaxis]\n",
    "        eigenfaces_to_use = self.eigenfaces[:,:self.number_of_components]\n",
    "        return np.dot(eigenfaces_to_use.T, y_normalized)\n",
    "    \n",
    "    def find_closest(self, Y):\n",
    "        w_unknown = self.__find_weights(Y)\n",
    "        eps_k = np.sqrt(la.norm(np.subtract(self.weights, w_unknown.T), axis=1))\n",
    "        min_eps_k = round(np.min(eps_k), 1)\n",
    "        epsilon = round(self.calculate_epsilon(Y), 1)\n",
    "        closest_img = self.data[np.argmin(eps_k)]\n",
    "        \n",
    "        threshold = round(self.threshold, 1)\n",
    "#         print(\"Threshold:{}, Epsilon:{}, Epsilon_k:{}\".format(threshold, epsilon, min_eps_k))\n",
    "        \n",
    "        if epsilon >= threshold:\n",
    "            return closest_img, None\n",
    "        elif epsilon < self.threshold and min_eps_k >= threshold:\n",
    "            return closest_img, False\n",
    "        return closest_img, True\n",
    "        \n",
    "    \n",
    "    def calculate_epsilon(self, Y):\n",
    "        w_unknown = self.__find_weights(Y)\n",
    "        eigenfaces_to_use = self.eigenfaces[:,:self.number_of_components]\n",
    "        reconstructed = eigenfaces_to_use.dot(w_unknown).reshape(Y.shape) + self.mean\n",
    "        epsilon = np.sqrt(la.norm(Y.reshape(-1) - reconstructed.reshape(-1)))\n",
    "        return epsilon\n",
    "        \n",
    "    def predict(self, Y):\n",
    "        epsilon = self.calculate_epsilon(Y)\n",
    "        return epsilon < self.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add plots to PCA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotableClassifier(Classifier):\n",
    "    def __init__(super):\n",
    "        pass\n",
    "    \n",
    "    def plot_importance(self, n=10):\n",
    "        first_n_eigenvalues = self.eigenvals[:n]\n",
    "        importance = first_n_eigenvalues/np.sum(self.eigenvals)\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        df = pd.DataFrame({\n",
    "            'Percentage of variances': importance, \n",
    "            'Principal components number': [i+1 for i in range(n)],\n",
    "        })\n",
    "        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.barplot(\n",
    "            ax=ax,\n",
    "            x='Principal components number', \n",
    "            y='Percentage of variances', \n",
    "            data=df,\n",
    "            palette=sns.cubehelix_palette(8),\n",
    "        ).set_title(\n",
    "            'Amount of variances convered by {} principal components is {}%'.format(\n",
    "                n, \n",
    "                round(df['Percentage of variances'].sum()*100, 3),\n",
    "            ),\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def plot_dependence(self, thresholds=(0.95, 0.99)):\n",
    "        sum_of_eigenvals = np.sum(self.eigenvals)\n",
    "        first_threshold_reached = 0\n",
    "        second_threshold_reached = 0\n",
    "        dependence = [sum(self.eigenvals[:n+1])/sum_of_eigenvals for n in range(len(self.eigenvals))]\n",
    "        for i, n in enumerate(dependence):\n",
    "            if n > thresholds[0] and first_threshold_reached == 0:\n",
    "                first_threshold_reached = i\n",
    "            elif n > thresholds[1] and second_threshold_reached == 0:\n",
    "                second_threshold_reached = i\n",
    "                break\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'Sum of variances': dependence, \n",
    "            'Principal components number': [i+1 for i in range(len(self.eigenvals))],\n",
    "        })\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        sns.lineplot(\n",
    "            ax=ax,\n",
    "            x='Principal components number', \n",
    "            y='Sum of variances', \n",
    "            data=df,\n",
    "            palette=sns.color_palette(\"Blues_d\", len(self.eigenvals)),\n",
    "        ).set_title('Sum of variances. Thresholds={}. Number of components respectively={}'.format(\n",
    "            thresholds, (first_threshold_reached, second_threshold_reached)\n",
    "        ))\n",
    "        \n",
    "        ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%d'))\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(base=50))\n",
    "        plt.axhline(y=thresholds[0], color='green')\n",
    "        plt.axhline(y=thresholds[1], color='r')\n",
    "        plt.axvline(first_threshold_reached, color='green')\n",
    "        plt.axvline(second_threshold_reached, color='r')\n",
    "        plt.show()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def find_best_threshold(self, faces, non_faces, n=11):\n",
    "        f = IntProgress(min=0, max=n, description='Computing:', bar_style='info')\n",
    "        display(f)\n",
    "        \n",
    "        components = list(range(1,n+1))\n",
    "        face_errors = np.array([])\n",
    "        not_face_errors = np.array([])\n",
    "        thresholds = np.array([])\n",
    " \n",
    "        for k in components:\n",
    "            pca.calculate_weights(k)\n",
    "            thresholds = np.append(thresholds, pca.calculate_threshold())\n",
    "            face_errors = np.append(face_errors, np.mean([pca.calculate_epsilon(face) for face in faces]))\n",
    "            not_face_errors = np.append(not_face_errors, np.mean([pca.calculate_epsilon(image) for image in non_faces]))\n",
    "\n",
    "            f.value += 1\n",
    "            \n",
    "        err_avg = np.array([(face_errors[i] + not_face_errors[i]) / 2 for i in range(n)])\n",
    "        best = np.argmin(np.abs(err_avg - thresholds))\n",
    "            \n",
    "        df = pd.DataFrame({\n",
    "            'Components': components,\n",
    "            'Thresholds': thresholds,\n",
    "            'Faces errors': face_errors, \n",
    "            'Non faces errors': not_face_errors,\n",
    "            'Error avg': err_avg\n",
    "        })\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.lineplot(\n",
    "            ax=ax, \n",
    "            x='Components', \n",
    "            y='value', \n",
    "            hue='variable', \n",
    "            data=pd.melt(df, ['Components']),\n",
    "        ).set_title('Best number of components is: {}'.format(best+1))\n",
    "        sns.regplot(x=np.array([best+1]), y=np.array([err_avg[best]]), scatter=True, fit_reg=False, marker='o', scatter_kws={\"s\": 100})\n",
    "        return best+1\n",
    "    \n",
    "    def plot_eigenfaces_sample(self, n=10):\n",
    "        random_eigenfaces_indexes = random.sample(range(0, self.eigenfaces.shape[1]), n)\n",
    "        sample = [(self.eigenfaces.T[i].reshape(self.data[0].shape), \"\") for i in random_eigenfaces_indexes]\n",
    "        imgs_show(sample, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifier on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PlotableClassifier()\n",
    "pca.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.plot_importance(n=20).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.plot_dependence().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_number_of_components = pca.find_best_threshold(test, non_face_test, n=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.plot_eigenfaces_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce dimentionality of the image\n",
    "\n",
    "One can notice that alogirthm performs well on faces in comparision with other type of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimentionality_reduction_plot(test_image, pca, prinicipal_components_number):\n",
    "    img_show(test_image, \"Original\", figsize=(3,4))\n",
    "\n",
    "    format_img_title = lambda i, img: \"PC number={},\\nmse={}\".format(\n",
    "        prinicipal_components_number[i], \n",
    "        round(np.square(test_image - img).mean(), 2),\n",
    "    )\n",
    "\n",
    "    reduced_dimentionality_images = [pca.reduce_dimention(test_image, i).reshape(test_image.shape) for i in prinicipal_components_number]\n",
    "    images_to_plot = [(img, format_img_title(i, img)) for i, img in enumerate(reduced_dimentionality_images)]\n",
    "\n",
    "    imgs_show(images_to_plot, 1, 30)\n",
    "    \n",
    "dimentionality_reduction_plot(test[0], pca, [1, 5, 50, 100, 200, 300, 500, 1000])\n",
    "dimentionality_reduction_plot(non_face_images[0], pca, [1, 5, 50, 100, 200, 300, 500, 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets check how our solution will recognize the images in test datasets\n",
    "\n",
    "Firstly we need to select number of prinicipal components for reconstraction, then calculate wights and project test data on the prinicipal components space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.calculate_weights(best_number_of_components)\n",
    "pca.calculate_threshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These faces hasn't been seen buy the alogorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(512)\n",
    "imgs_show([(test[i], \"Face = {}\".format(pca.predict(test[i]))) for i in random.sample(range(0, len(test)), 8)], 1, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images are not faces at all. Some of the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(256)\n",
    "imgs_show([(non_face_test[i], \"Face={}\".format(pca.predict(non_face_test[i]))) for i in random.sample(range(0, len(non_face_test)), 8)], 1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [len(test), len(non_face_test)]\n",
    "y_pred = [\n",
    "    sum([pca.predict(img) for img in test]),\n",
    "    len(non_face_test) - sum([pca.predict(img) for img in non_face_test])\n",
    "]\n",
    "\n",
    "tp = y_pred[0]\n",
    "tn = y_pred[1]\n",
    "fp = y_true[1] - y_pred[1]\n",
    "fn = y_true[0] - y_pred[0]\n",
    "df_cm = pd.DataFrame([[tp, tn], [fp, fn]] , range(2), range(2))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", annot_kws={\"size\": 20})\n",
    "\n",
    "precision=tp/(tp+fp)\n",
    "recall=tp/(tp+fn)\n",
    "print(\"Accuracy={}\".format((tp + tn)/(tp+tn+fp+fn)))\n",
    "print(\"Precision={}\".format(precision))\n",
    "print(\"Recall={}\".format(recall))\n",
    "print(\"F1 Score={}\".format(2*(precision*recall/(precision+recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition\n",
    "\n",
    "For this task another dataset called AT&T Laboratories Cambridge is used. This is done because the each class has the same number of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_faces = read_folder('./att_faces/', '.pgm')\n",
    "att_faces_train, att_faces_test = train_test_split(att_faces, test_size=.25, random_state=512, shuffle=True)\n",
    "print(\"Train set shape: {}. Test set shape: {}\".format(len(att_faces_train), len(att_faces_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_number_of_components(train, test):\n",
    "    f = IntProgress(min=0, max=len(train)//2, description='Computing:', bar_style='info')\n",
    "    display(f)\n",
    "    \n",
    "    face_recognition_pca = Classifier()\n",
    "    face_recognition_pca.fit(np.array(train))\n",
    "    accuracy = []\n",
    "    for n in range(len(train)//2):\n",
    "        face_recognition_pca.calculate_weights(n+1)\n",
    "        face_recognition_pca.calculate_threshold()\n",
    "        count = 0\n",
    "        for img in test:\n",
    "            _, face_in_db = face_recognition_pca.find_closest(img)\n",
    "            if face_in_db:\n",
    "                count+=1\n",
    "        f.value += 1\n",
    "        accuracy.append(count/len(test))\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = find_best_number_of_components(att_faces_train, att_faces_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Accuracy': accuracy,\n",
    "    'Components number': [i + 1 for i in range(len(att_faces_train)//2)]\n",
    "})\n",
    "\n",
    "best = np.argmax(accuracy)\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.lineplot(\n",
    "    ax=ax, \n",
    "    y='Accuracy', \n",
    "    x='Components number',\n",
    "    data=df,\n",
    ").set_title(\"Accuracy to number of components\")\n",
    "sns.regplot(x=np.array([best+1]), y=np.array([accuracy[best]]), scatter=True, fit_reg=False, marker='o', scatter_kws={\"s\": 120})\n",
    "plt.axhline(y=accuracy[best], color='r')\n",
    "plt.axvline(best+1, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognition_pca = PlotableClassifier()\n",
    "face_recognition_pca.fit(np.array(att_faces_train))\n",
    "\n",
    "face_recognition_pca.calculate_weights(best+1)\n",
    "face_recognition_pca.calculate_threshold()\n",
    "\n",
    "random.seed(256)\n",
    "for i in random.sample(range(0, len(att_faces_test)), 5):\n",
    "    original = att_faces_test[i]\n",
    "    closest, face_in_db = face_recognition_pca.find_closest(att_faces_test[i])\n",
    "    imgs_show([(original, \"Original\"), (closest, \"Is face in db:{}\".format(face_in_db))], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
